{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756b93d4-efac-4b53-bc75-29ab680ff411",
   "metadata": {},
   "source": [
    "# 🧠 Fairness in Machine Learning — Hands-on Workshop\n",
    "## Welcome! In this workshop, you'll:\n",
    "#### - Train a model to predict income\n",
    "#### - Evaluate fairness across **gender**\n",
    "#### - Apply a fairness mitigation technique (Equalized Odds)\n",
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c42ab-847c-47bc-b8ee-9c7a37ce0929",
   "metadata": {},
   "source": [
    "# 📦 Install required packages (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45537a-f0bf-479f-8cfc-7499183bc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pip # Make sure pip is up to date\n",
    "!pip install -q numpy pandas matplotlib scikit-learn seaborn fairlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48df9ab-0715-4b3d-80d6-d2c805236430",
   "metadata": {},
   "source": [
    "# 📚 Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d3239-9027-49ba-b9ed-0f38626dbe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data manipulation tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Fairness tools\n",
    "from fairlearn.metrics import MetricFrame, true_positive_rate, false_positive_rate\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07082522-c745-45b5-a5b8-71266b94976f",
   "metadata": {},
   "source": [
    "# 📥 Step 2: Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf63a8d-385e-456c-9b84-d33db39a1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/saravrajavelu/Adult-Income-Analysis/refs/heads/master/adult.csv\"\n",
    "\n",
    "# Read the data from the url\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Encode target label\n",
    "df['income_higher_than_50k'] = df['income'].map({'<=50K':0, '>50K':1})\n",
    "df = df.replace('?', np.nan) # This dataset uses '?' as a placeholder for missing data, let's use the best practices with np.nan\n",
    "\n",
    "# Preview the cleaned data\n",
    "df.head()\n",
    "# Todo: Inspect the data and think about what each column means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5def7-9439-4b2b-b96f-bba94be71f0a",
   "metadata": {},
   "source": [
    "# Step 3: Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f44ab9-30f0-426c-9e10-cf218029d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 3.1 CHECK SHAPE & TYPES ─────────────────────────────\n",
    "print(\"Records, Features:\", df.shape)\n",
    "df.info()\n",
    "# TODO: Note which columns are numeric vs object (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d427b199-3829-44f4-b8df-4c4c636f273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 3.2 TARGET DISTRIBUTION ────────────────────────────\n",
    "df['income'].value_counts().plot(\n",
    "    kind='bar', title='Income (>50K vs <=50K) Counts'\n",
    ")\n",
    "plt.show()\n",
    "# TODO: What % earn >50K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b6d97-6b17-4843-a515-6e0cdc7ad673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 2.3 FEATURE VISUALIZATIONS ─────────────────────────\n",
    "# Categorical: education\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='education', data=df,\n",
    "              order=df['education'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Education Levels\")\n",
    "plt.show()\n",
    "\n",
    "# Numeric: age distribution\n",
    "sns.histplot(df['age'], kde=True)\n",
    "plt.title(\"Age Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd26fa48-cd59-4480-b998-adc6b7e7c763",
   "metadata": {},
   "source": [
    "## Correlation Matrix of Numeric Features\n",
    "We often start by looking at how numeric features correlate with each other **and** with our target (`income`).  \n",
    "High positive or negative correlations can hint at strong predictors or multicollinearity issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412146d-aa23-4c5c-87bc-35836a2089a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns + our binary target\n",
    "numeric_cols = ['age', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "corr_df = df[numeric_cols + ['income_higher_than_50k']].corr()\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(corr_df, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Matrix of Numeric Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0335bf96-01d6-4f01-baa1-84f380264511",
   "metadata": {},
   "source": [
    "## Income Proportions by Education Level\n",
    "For a categorical feature, a **stacked bar chart** shows the proportion of each income class within each category.  \n",
    "This reveals which education levels have higher fractions of >50K earners.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84bb1d-e9f9-4f96-a938-490aff6c7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_prop = pd.crosstab(df['education'], df['income'], normalize='index')\n",
    "\n",
    "edu_prop.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(10,5),\n",
    "    colormap='Pastel1'\n",
    ")\n",
    "plt.title(\"Proportion of Income Categories by Education Level\")\n",
    "plt.ylabel(\"Proportion of Group\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec60f7-2d6d-4b49-bd39-9600b80d881d",
   "metadata": {},
   "source": [
    "## Age vs Hours-per-Week\n",
    "A scatterplot of **age** against **hours-per-week**, colored by income, can show whether high earners cluster in certain age or work-hour ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4989a-c960-4a4c-83b8-654590ddebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x='age', y='hours-per-week',\n",
    "    hue='income', data=df, alpha=0.5\n",
    ")\n",
    "plt.title(\"Age vs Hours-per-Week by Income Category\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eef0dc-9ac8-4db1-a018-029c2cb7b7d2",
   "metadata": {},
   "source": [
    "## Marital Status Distribution among >50K Earners\n",
    "Pie charts can quickly show which marital statuses are most common among high earners.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55e161-63a8-4996-982e-1eddbe23de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_status = df[df['income_higher_than_50k']==1]['marital-status'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "high_status.plot(\n",
    "    kind='pie',\n",
    "    startangle=90,\n",
    "    colormap='tab20',\n",
    "    labels=None  # Hide labels on pie\n",
    ")\n",
    "plt.legend(labels=high_status.index, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Marital Status Distribution among >50K Earners\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb219f-9f53-4978-8828-38885bb7bc04",
   "metadata": {},
   "source": [
    "## Top 10 Occupations for >50K Earners\n",
    "A horizontal bar chart of the most frequent occupations among high earners can highlight which roles are most associated with higher income.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da3f09-98e2-43a1-b1e8-e29f9529eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "top_occ = df[df['income'] == '>50K']['occupation'].value_counts().nlargest(10)\n",
    "top_occ_df = top_occ.reset_index()\n",
    "top_occ_df.columns = ['occupation', 'count']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(\n",
    "    data=top_occ_df,\n",
    "    y='occupation',\n",
    "    x='count',\n",
    "    hue='occupation',      # required to use palette safely\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title(\"Top 10 Occupations among >50K Earners\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Occupation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260da9c-b887-4a1b-a37c-21c5becaa619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "a4_dims = (20, 5)\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "ax = sns.violinplot(x=\"occupation\", y=\"age\", hue=\"income\",\n",
    "                    data=df, gridsize=100, palette=\"muted\", split=True, saturation=0.75)\n",
    "ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631c7a5-0513-4a7d-a2ba-656da969858d",
   "metadata": {},
   "source": [
    "\n",
    "## Why use?\n",
    " \n",
    "- Correlation heatmap highlights which features move together—and how strongly they relate to the target.\n",
    "- Boxplots and scatterplots help spot outliers and distribution differences between income groups.\n",
    "- Stacked bars show category-level propensities.\n",
    "- Pie and occupation charts give intuitive views of group makeup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd41683-ccd3-4ab9-8e79-2fb999458fce",
   "metadata": {},
   "source": [
    "# Step 4: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5efc8-da31-48c4-9a8e-7ecc2f5281c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 4.1 HANDLE MISSING VALUES ───────────────────────────\n",
    "print((df.isna()).sum()) # Check how many and what values are missing\n",
    "old_size = len(df)\n",
    "print() # For spacing\n",
    "print(f'Size of dataset = {len(df)}')\n",
    "df = df.dropna()         # simple drop for workshop since missing data is not too big\n",
    "# TODO: How many rows were removed?\n",
    "print(f'Size of dataset after removing missing values {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8f44d-98d6-4f40-a6c6-a189e5b7a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 4.2 ENCODE CATEGORICALS ────────────────────────────\n",
    "# We use one-hot encoding instead of numeric labels because decision trees split data based on feature values. \n",
    "# If we assign numbers like `Private = 1`, `State-gov = 2`, it introduces a fake order (e.g., 2 > 1), which misleads the model.\n",
    "# This is called One-hot encoding and it avoids this by creating separate 0/1 columns for each category, \n",
    "# letting the tree split cleanly on exact matches without assuming any order.\n",
    "# It's more accurate and reliable for decision trees.\n",
    "\n",
    "cat_cols = df.select_dtypes('object').columns.drop('income')\n",
    "df_enc = pd.get_dummies(df, columns=cat_cols)\n",
    "# TODO: Inspect df_enc.columns to see new dummy columns\n",
    "# SPEAKER_TODO talk about this in terms of decision trees why this would be nice!\n",
    "df_enc.columns\n",
    "df_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6da4b-05d6-4887-8c22-9abeb06b1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 4.3 BINARY TARGET & SCALING ────────────────────────\n",
    "# Scale numeric features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_cols = ['age','fnlwgt','educational-num',\n",
    "            'capital-gain','capital-loss','hours-per-week']\n",
    "scaler = StandardScaler()\n",
    "df_enc[num_cols] = scaler.fit_transform(df_enc[num_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a4074a-f49b-48ad-82e1-16ec8c9a402d",
   "metadata": {},
   "source": [
    "# Step 5: Model Training & Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4087c8-dcb7-4823-b1a1-59e7bab60097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── TRAIN/TEST SPLIT ────────────────────────────────\n",
    "X_labels = df_enc.drop('income', axis=1)\n",
    "X = X_labels.drop('income_higher_than_50k', axis=1)\n",
    "y = df_enc['income_higher_than_50k']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c9bde-ea81-4a69-b264-05b2d685c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5.1 TRAIN MODEL ─────────────────────────────────────\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# TODO: This may take ~30 seconds – watch for convergence warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a37742-d273-42fe-8dd0-88a44886cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5.2 PREDICT & ACCURACY ──────────────────────────────\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3fb6e-e193-4a8e-8341-12e3694b6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5.3 DETAILED METRICS ───────────────────────────────\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf33ff3-9335-4e5a-849e-937fe12eb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5.4 CONFUSION MATRIX ───────────────────────────────\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['<=50K','>50K'])\n",
    "disp.plot()\n",
    "plt.show()\n",
    "# TODO: Identify TP, FP, FN, TN cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7543f-c4a1-48a2-9b6c-8484d42239f0",
   "metadata": {},
   "source": [
    "# Step 6: Fairness Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addaabd1-37d8-4ecd-8545-0bb3b71a5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── 5.1 EXTRACT GENDER INFO ─────────────────────────────\n",
    "# # We need the original 'sex' column before one-hot:\n",
    "# sex = df['gender']\n",
    "# # .reset_index(drop=True)\n",
    "# test_sex = sex[X_test.index]\n",
    "# # TODO: Ensure test_sex aligns with X_test indices\n",
    "# mask_m = (test_sex == 'Male')\n",
    "# mask_f = (test_sex == 'Female')\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# acc_m = accuracy_score(y_test[mask_m], y_pred[mask_m])\n",
    "# acc_f = accuracy_score(y_test[mask_f], y_pred[mask_f])\n",
    "\n",
    "# print(f\"Male accuracy:   {acc_m:.3f}\")\n",
    "# print(f\"Female accuracy: {acc_f:.3f}\")\n",
    "# # TODO: Discuss why these may differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7d9fa-b20e-48d9-9435-29270c152bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Define a reusable plotting function ────────────────────────────────\n",
    "def plot_percentage_by_group(ax, df, col_name, x_label=None, y_label=None):\n",
    "    \"\"\"\n",
    "    Plots the percentage of people with income >50K for each category in `col_name`.\n",
    "    \n",
    "    ax        : a matplotlib Axes object\n",
    "    df        : DataFrame containing 'incomeHigherThan50k' and col_name\n",
    "    col_name  : the column to group by (e.g. 'sex' or 'race')\n",
    "    x_label   : optional label for x-axis\n",
    "    y_label   : optional label for y-axis\n",
    "    \"\"\"\n",
    "    # Total count per group\n",
    "    group_sizes = df.groupby(col_name).size()\n",
    "    # Count of >50K per group\n",
    "    higher_income = df[df['income_higher_than_50k'] == 1].groupby(col_name).size()\n",
    "    # Compute proportions (fill missing groups with 0)\n",
    "    percentages = (higher_income / group_sizes).fillna(0)\n",
    "    \n",
    "    # Plot as bar chart\n",
    "    percentages.plot(\n",
    "        kind='bar',\n",
    "        ax=ax,\n",
    "        title=f'Proportion >50K by {col_name}'\n",
    "    )\n",
    "    \n",
    "# ─── Create side-by-side plots for Gender & Race ─────────────────────────\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14,5))\n",
    "\n",
    "plot_percentage_by_group(\n",
    "    axes[0], df, 'gender',\n",
    "    x_label='Gender', y_label='Proportion >50K'\n",
    ")\n",
    "plot_percentage_by_group(\n",
    "    axes[1], df, 'race',\n",
    "    x_label='Race', y_label='Proportion >50K'\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00efb1-d0af-4cb1-9d73-b09a0cc32bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_rates(y_true, y_pred, groups):\n",
    "    records = []\n",
    "    for g in groups.unique():\n",
    "        mask = (groups == g)\n",
    "        tn, fp, fn, tp = confusion_matrix(\n",
    "            y_true[mask], y_pred[mask], labels=[0,1]\n",
    "        ).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        records.append({'group': g, 'TPR': tpr, 'FPR': fpr})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Recover original sensitive attributes for the test set\n",
    "gender_test = df.loc[X_test.index, 'gender']          # 'Male' or 'Female'\n",
    "race_test = df.loc[X_test.index, 'race']        # e.g. 'White', 'Black', etc.\n",
    "\n",
    "# 1) Get the rates per sensitive group\n",
    "gender_rates = compute_group_rates(y_test, y_pred, groups=gender_test)\n",
    "race_rates = compute_group_rates(y_test, y_pred, groups=race_test)    \n",
    "\n",
    "# Melt data together for gender\n",
    "gender_long = gender_rates.melt(\n",
    "    id_vars='group',\n",
    "    value_vars=['TPR','FPR'],\n",
    "    var_name='Metric',\n",
    "    value_name='Rate'\n",
    ")\n",
    "\n",
    "# Melt for race\n",
    "race_long = race_rates.melt(\n",
    "    id_vars='group',\n",
    "    value_vars=['TPR','FPR'],\n",
    "    var_name='Metric',\n",
    "    value_name='Rate'\n",
    ")\n",
    "\n",
    "# 2a) Plot gender metrics\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(\n",
    "    data=gender_long,\n",
    "    x='Metric',        # TPR vs FPR\n",
    "    y='Rate',\n",
    "    hue='group'        # Male vs Female\n",
    ")\n",
    "plt.ylim(0,1)\n",
    "plt.title('True Positive & False Positive Rates by Gender')\n",
    "plt.ylabel('Rate')\n",
    "plt.legend(title='Gender')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2b) Plot race metrics\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(\n",
    "    data=race_long,\n",
    "    x='Metric',        # TPR vs FPR\n",
    "    y='Rate',\n",
    "    hue='group'        # each race category\n",
    ")\n",
    "plt.ylim(0,1)\n",
    "plt.title('True Positive & False Positive Rates by Race')\n",
    "plt.ylabel('Rate')\n",
    "plt.legend(title='Race', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9e8f6-e6a2-44c9-9b55-823651779299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_equalized_odds(rates_df, attr_name):\n",
    "    \"\"\"\n",
    "    Given a DataFrame with columns ['group','TPR','FPR'], compute:\n",
    "      - max/min TPR & FPR\n",
    "      - absolute gap (max - min)\n",
    "      - ratio   (min / max) for four-fifths test\n",
    "    \n",
    "    Returns a DataFrame summarizing these metrics for the protected attribute.\n",
    "    \"\"\"\n",
    "    # Extract max/min\n",
    "    tpr_max, tpr_min = rates_df['TPR'].max(), rates_df['TPR'].min()\n",
    "    fpr_max, fpr_min = rates_df['FPR'].max(), rates_df['FPR'].min()\n",
    "    \n",
    "    # Compute metrics\n",
    "    summary = {\n",
    "        'Attribute': attr_name,\n",
    "        # 'TPR_max': tpr_max,\n",
    "        # 'TPR_min': tpr_min,\n",
    "        'TPR_gap': tpr_max - tpr_min,\n",
    "        'TPR_ratio': (tpr_min / tpr_max) if tpr_max>0 else float('nan'),\n",
    "        # 'FPR_max': fpr_max,\n",
    "        # 'FPR_min': fpr_min,\n",
    "        'FPR_gap': fpr_max - fpr_min,\n",
    "        'FPR_ratio': (fpr_min / fpr_max) if fpr_max>0 else float('nan'),\n",
    "    }\n",
    "    return pd.DataFrame([summary])\n",
    "\n",
    "gender_summary = evaluate_equalized_odds(gender_rates, \"Gender\")\n",
    "race_summary   = evaluate_equalized_odds(race_rates,   \"Race\")\n",
    "\n",
    "# Combine and display\n",
    "fairness_summary = pd.concat([gender_summary, race_summary], ignore_index=True)\n",
    "fairness_summary.style.format({\n",
    "    'TPR_max':'{:.2f}', 'TPR_min':'{:.2f}', 'TPR_gap':'{:.2f}', 'TPR_ratio':'{:.2f}',\n",
    "    'FPR_max':'{:.2f}', 'FPR_min':'{:.2f}', 'FPR_gap':'{:.2f}', 'FPR_ratio':'{:.2f}',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03406bce-ddad-4d8f-a325-c0f3da114fe4",
   "metadata": {},
   "source": [
    "# Step 7: Introduce fairlearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464a1eb-a2e2-4d70-93ba-dfbacff0be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "from fairlearn.metrics import MetricFrame, true_positive_rate, false_positive_rate\n",
    "\n",
    "# Prepare Sensitive Features DataFrames\n",
    "# Extract **gender** for your train/test splits so Fairlearn can enforce fairness across this feature.\n",
    "\n",
    "# 1) isolate just gender\n",
    "gender_train = df.loc[X_train.index, 'gender']\n",
    "gender_test  = df.loc[X_test.index,  'gender']\n",
    "\n",
    "# Quick preview\n",
    "print(\"Training sensitive features:\\n\", gender_train.head())\n",
    "print(\"\\nTest sensitive features:\\n\",  gender_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ec28f-1efa-4929-9b33-f977a5c27b6f",
   "metadata": {},
   "source": [
    "\n",
    "### Now we train a Fairness‐Aware Model\n",
    "By wrapping a `LogisticRegression` in `ExponentiatedGradient` to enforce Equalized Odds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6352a8-dedf-4cda-9253-6b730b4f8f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) define base estimator\n",
    "base_est = model # The model we trained earlier\n",
    "\n",
    "# 3) wrap in ExponentiatedGradient with EqualizedOdds on gender\n",
    "mitigator = ExponentiatedGradient(\n",
    "    estimator=base_est,\n",
    "    constraints=EqualizedOdds(),\n",
    "    eps=0.01              # defines how much unequal treatment you're willing to accept across protected groups\n",
    ")\n",
    "\n",
    "# 4) fit on training data + gender\n",
    "mitigator.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    sensitive_features=gender_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728374d-4b25-4625-ad37-5da620935bc8",
   "metadata": {},
   "source": [
    "### Evaluate new improved model\n",
    "Check overall accuracy, classification report, then confirm TPR/FPR parity across gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ddc59-e0bf-4df3-9190-dc8c2b8e6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) predict & evaluate\n",
    "y_pred_fair = mitigator.predict(X_test)\n",
    "print(\"Fair (gender-only) model accuracy:\", accuracy_score(y_test, y_pred_fair))\n",
    "print(classification_report(y_test, y_pred_fair))\n",
    "\n",
    "# 6) compute TPR & FPR by gender\n",
    "metric_frame = MetricFrame(\n",
    "    metrics={'TPR': true_positive_rate, 'FPR': false_positive_rate},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_fair,\n",
    "    sensitive_features=gender_test\n",
    ")\n",
    "print(\"\\nEqualized Odds metrics by gender:\")\n",
    "print(metric_frame.by_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ae4d3-a9b7-498f-bfdc-1e2aa263ff1d",
   "metadata": {},
   "source": [
    "### Visualize TPR & FPR\n",
    "Plot side‐by‐side bar charts to confirm the disparities have been reduced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15041f7-1f09-416c-84cd-308a9bd69408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) plot gender bars\n",
    "gender_long = metric_frame.by_group.reset_index().melt(\n",
    "    id_vars='gender',\n",
    "    value_vars=['TPR','FPR'],\n",
    "    var_name='Metric',\n",
    "    value_name='Rate'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(\n",
    "    data=gender_long,\n",
    "    x='Metric',\n",
    "    y='Rate',\n",
    "    hue='gender',\n",
    "    errorbar=None\n",
    ")\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"True Positive & False Positive Rates by Gender\")\n",
    "plt.ylabel(\"Rate\")\n",
    "plt.legend(title='Gender')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Assuming `gender_summary` is your 1-row DataFrame from evaluate_equalized_odds\n",
    "summary_table = pd.DataFrame({\n",
    "    'attr': ['Gap', 'Ratio'],\n",
    "    'TPR': [gender_summary.at[0, 'TPR_gap'],\n",
    "            gender_summary.at[0, 'TPR_ratio']],\n",
    "    'FPR': [gender_summary.at[0, 'FPR_gap'],\n",
    "            gender_summary.at[0, 'FPR_ratio']]\n",
    "})\n",
    "\n",
    "# Display it nicely in Jupyter\n",
    "summary_table.style.set_table_styles([\n",
    "    {'selector': 'thx', 'props': [('text-align', 'center')]},\n",
    "    {'selector': 'td', 'props': [('text-align', 'center')]}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ab640-075f-44d3-ae6c-bfc10a08b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score,\n",
    "    \"Precision\": lambda y_true, y_pred: precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": lambda y_true, y_pred: recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1-Score\": lambda y_true, y_pred: f1_score(y_true, y_pred, zero_division=0)\n",
    "}\n",
    "\n",
    "# Compute values\n",
    "scores = {\n",
    "    \"Biased Model\": [],\n",
    "    \"Fair Model\": []\n",
    "}\n",
    "\n",
    "for _, func in metrics.items():\n",
    "    scores[\"Biased Model\"].append(func(y_test, y_pred))\n",
    "    scores[\"Fair Model\"].append(func(y_test, y_pred_fair))\n",
    "\n",
    "# Create DataFrame\n",
    "score_df = pd.DataFrame(scores, index=metrics.keys()).T\n",
    "\n",
    "# Plot\n",
    "ax = score_df.plot(kind='bar', figsize=(9,6), ylim=(0,1.05))\n",
    "plt.title(\"Biased vs Fair Model Performance\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Metric\", loc='upper right')\n",
    "\n",
    "# Add value labels on each bar\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc59756-10e3-459f-bef5-f48790361119",
   "metadata": {},
   "source": [
    "## ✅ Recap & Next Steps\n",
    "\n",
    "In this workshop, we:\n",
    "\n",
    "- Explored the **UCI Adult Income dataset** and identified class and group imbalances\n",
    "- Performed **Exploratory Data Analysis (EDA)** to uncover patterns and potential bias\n",
    "- Trained a baseline **Logistic Regression model** and evaluated performance\n",
    "- Measured fairness using **True Positive Rate (TPR)** and **False Positive Rate (FPR)** across gender and race\n",
    "- Applied two fairness mitigation technique **In-processing** using `ExponentiatedGradient` to train a fairness-aware model directly\n",
    "- Compared models using accuracy, precision, recall, F1-score, and group-level fairness metrics\n",
    "\n",
    "---\n",
    "\n",
    "### 🔭 Next Steps\n",
    "\n",
    "- 💡 **Experiment with other fairness metrics**, such as demographic parity or equal opportunity\n",
    "- ⚖️ Try **different sensitive attributes** (e.g., age groups)\n",
    "- 📊 Visualize **fairness vs accuracy tradeoffs** by tuning the `eps` parameter\n",
    "- 🤖 Try using **different base models** (e.g., Random Forest, Gradient Boosting)\n",
    "\n",
    "---\n",
    "\n",
    "> Thank you for participating! 🎉  \n",
    "> Remember: fairness is not a one-time fix — it’s a design principle.  \n",
    "> Keep questioning, validating, and improving your models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
